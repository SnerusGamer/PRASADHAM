COMPILER CONSTRUCTION
LAB

By

Sindhuja.p

Course Code: GR22A3068
L/T/P/C :0/ 0/ 4/ 2

III Year I Semester

Course Outcomes:

1.Implement the techniques of Lexical Analyzer

2.Use lex to recognize token

3.Implement basic programs using yaac

4.Acquire practical knowledge on parsing

5.Implement three address code generation

LIST OF EXPERIMENTS:

TASK 1: Introduction to lex tools.

TASK 2: Lex program to count the number of words, characters, blank spaces and lines

TASK 3: LEX program to identify REAL PRECISION of the given number

TASK 4: LEX Program to recognize tokens

TASK 5: Implement a program to Elimination of Left Recursion in a grammar.

TASK 6: Program to implement Predictive Parsing.

TASK 7: Design LALR bottom-up parser for the above language.

TASK 8: Write program to generate machine code from the abstract syntax tree

generated by the parser

TASK 9: Introduction to YACC.

TASK 10: Convert the BNF rules into Yacc form and Write code to generate abstract

syntax tree.

TASK 11: YACC Program of an advanced desk calculator.

TASK 12: Program to Implement 3 Address Code.

Textbooks:

1.Compilers: Principles, Techniques and Tools, V. Aho, R. Sethi and J. Ullman.

2.lex&yacc – John R. Levine, Tony Mason, Doug Brown, O’reilly

References:

1.The Design and Evolution of C++, Bjarne Stroustrup.

2.Modern Compiler Design- Dick Grune, Henry E. Bal, Cariel T. H. Jacobs, Wileydre

Compiler :

A compiler is system software that translates the source program written in
a high-level language into a low-level language.

The compilation process of source code is divided into several phases in
order to ease the process of development and designing.

The phases work in sequence as the output of the previous phase is utilized
in the next phase.

Phases of compiler:

Lexical analysis :

It is the first step of compiler design, it takes the input as a stream of characters
and gives the output as tokens also known as tokenization.

The tokens can be classified into identifiers, Sperators, Keywords, Operators,
Constant and Special Characters.

It has three phases:

Tokenization: It takes the stream of characters and converts it into tokens.

Error Messages: It gives errors related to lexical analysis such as exceeding
length, unmatched string, etc.

Eliminate Comments: Eliminates all the spaces, blank spaces, new lines, and
indentations.

Token :

It is basically a sequence of characters that are treated as a unit as it cannot be further
broken down. In programming languages like C language- keywords (int, char, float,
const, goto, continue, etc.) identifiers (user-defined names), operators (+, -, *, /),
delimiters/punctuators like comma (,), semicolon(;), braces ({ }), etc. , strings can be
considered as tokens.

Example :

int a = 10; //Input Source code

Tokens

int (keyword), a(identifier), =(operator), 10(constant) and ;(punctuation-semicolon)

Total number of tokens=5

LEX TOOL

TASK 1: Introduction to lex tools.

Lex :

Lex is a tool or a computer program that generates Lexical Analyzers
(converts the stream of characters into tokens). The Lex tool itself is a
compiler. The Lex compiler takes the input and transforms that input
into input patterns. It is commonly used with YACC(Yet Another
Compiler Compiler). It was written by Mike Lesk and Eric Schmidt.

Function of Lex :

1. In the first step the source code which is in the Lex language having the file
name ‘File.l’ gives as input to the Lex Compiler commonly known as Lex to
get the output as lex.yy.c.

2. After that, the output lex.yy.c will be used as input to the C compiler which
gives the output in the form of an ‘a.out’ file, and finally, the output file a.out
will take the stream of character and generates tokens as output.

lex.yy.c: It is a C program.

File.l: It is a Lex source program

a.out: It is a Lexical analyzer

Lex File Format

A Lex program consists of three parts and is separated by %% delimiters:-

Declarations

%%

Translation rules

%%

Auxiliary procedures

Declarations: The declarations include declarations of variables.

Translation rules: These rules consist of Pattern and Action.

Auxiliary procedures: The Auxilary section holds auxiliary functions used in
the actions.

%{

#include<stdio.h>

int vow=0, con=0;

%}

%%

[ \t\n]+ ;

[aeiouAEIOU]+ {vow++;}

[a-zA-Z] {con++;}

%%

int main( )

{

printf("Enter some input string:\n");

yylex();

printf("Number of vowels=%d\n",vow);

printf("Number of consonants=%d\n",con);

}

int yywrap( )

{

return 1;

}

TASK 2: Lex program to count the number of words, characters,
blank spaces and lines

%{

#include<stdio.h>

int sc=0,wc=0,lc=0,cc=0;

%}

%%

[\n] { lc++; cc+=yyleng;}

[ \t] { sc++; cc+=yyleng;}

[^\t\n ]+ { wc++; cc+=yyleng;}

%%

int main(int argc ,char* argv[ ]) // int main()

{

printf("Enter the input:\n");

yylex();

printf("The number of lines=%d\n",lc);

printf("The number of spaces=%d\n",sc);

printf("The number of words=%d\n",wc);

printf("The number of characters are=%d\n",cc);

}

int yywrap( )

{

return 1;

}

Then the scanner receives an end-of-file indication from YY_INPUT, it then checks
the yywrap() function. If yywrap() returns false (zero), then it is assumed that the function has
gone ahead and set up yyin to point to another input file, and scanning continues. If it returns
true (non-zero), then the scanner terminates, returning 0 to its caller.

TASK 3: LEX program to identify REAL PRECISION of the given number

%{

#include<stdio.h>

%}

%%

[+-]?[0-9]+\.[0-9]{1,7}([eE][+-]?[0-9]+)? { printf("Single Precision Real Number\n"); }

[+-]?[0-9]+\.[0-9]{8,16}([eE][+-]?[0-9]+)? { printf("Double Precision Real Number\n"); }

[+-]?[0-9]+\.([eE][+-]?[0-9]+)? { printf("Real Number with No Fractional Part\n"); }

[+-]?[0-9]+ { printf("Integer Number\n"); }

%%

int main()

{

printf("Enter a number: ");

yylex();

return 0;

}

int yywrap()

{

return 1;

}

TASK 4: LEX Program to recognize tokens

%{

/* C code section - includes standard libraries */

#include <stdio.h>

%}

/* Definitions */

DIGIT [0-9]

LETTER [a-zA-Z]

ID {LETTER}({LETTER}|{DIGIT})*

%%

/* Rules section */

"if" { printf("KEYWORD: if\n"); }

"else" { printf("KEYWORD: else\n"); }

"for" { printf("KEYWORD: for\n"); }

{ID} { printf("IDENTIFIER: %s\n", yytext); }

{DIGIT}+ { printf("NUMBER: %s\n", yytext); }

"+" { printf("OPERATOR: +\n"); }

"-" { printf("OPERATOR: -\n"); }

"*" { printf("OPERATOR: *\n"); }

"/" { printf("OPERATOR: /\n"); }

"=" { printf("OPERATOR: =\n"); }

\n|\t| " " { /* Ignore whitespace */ }

. { printf("UNKNOWN TOKEN: %s\n", yytext); }

%%

/* C code section */

int main() {

yylex(); // Call the lexical analyzer

return 0;

}

int yywrap() {

return 1;

}

TASK 5: Implement a program to Elimination of Left Recursion in a
grammar.

%{

#include <stdio.h>

#include <string.h>

void eliminate_left_recursion(char* non_terminal, char* alpha, char* beta);

%}

%%

// Rule to match a non-terminal followed by "->"

[A-Z] "->" {

char non_terminal[2];

non_terminal[0] = yytext[0]; // Store the non-terminal

non_terminal[1] = '\0'; // Null-terminate the string

// Prompt user to enter production rules for the non-terminal

printf("Enter production for %s (format: α | β): ", non_terminal);

char input[100], alpha[50], beta[50];

fgets(input, sizeof(input), stdin);

// Split input at the '|'

sscanf(input, "%[^|]|%s", alpha, beta);

// Call function to eliminate left recursion

eliminate_left_recursion(non_terminal, alpha, beta);

}

// Rule to ignore any other inputs

. { /* Ignore other inputs */ }

%%

// Function to eliminate left recursion from the given productions

void eliminate_left_recursion(char* non_terminal, char* alpha, char* beta) {

printf("Original Production: %s -> %s%s | %s\n", non_terminal,
non_terminal, alpha, beta);

char new_non_terminal[3];

snprintf(new_non_terminal, sizeof(new_non_terminal), "%s'", non_terminal);
// Create new non-terminal

// Print the transformed productions

printf("After removing left recursion:\n");

printf("%s -> %s%s\n", non_terminal, beta, new_non_terminal); //
Non-left-recursive rule

printf("%s -> %s%s | ε\n", new_non_terminal, alpha, new_non_terminal); //
Left-recursive rule

}

int main() {

printf("Enter grammar productions (terminate with CTRL+D):\n");

yylex(); // Start the lexical analysis

return 0;

}

Output:A->Aa|b

A->bA’

A’->aA’|ε

TASK 6: Program to implement Predictive Parsing.

#include <stdio.h>

#include <ctype.h> // for isdigit function

#include<stdlib.h>

char input[100];

Int pos = 0; char lookahead;

// Function prototypes for recursive descent parsing

void E();

void Eprime();

void T();

void Tprime();

void F();

void match(char t);

// Helper function to get the next character char nextToken()

{

return input[pos++];

}

// Function to report a syntax error

void syntaxError()

{

printf("Syntax Error!\n");

exit(1);

}

// Function to match a token and advance the input

void match(char t)

{

if (lookahead == t)

{

lookahead = nextToken();

}

Else

{

syntaxError();

}

}

// Production: E → T E’

void E() {

T();

Eprime(); }

// Production:E' → + T E' | ε

void Eprime() {

if (lookahead == '+’)

{

match('+’);

T(); Eprime();

}

// E' → ε (epsilon, do nothing)

}

// Production: T → F T’

void T() {

F();

Tprime(); }

// Production: T' → * F T' | ε

void Tprime() {

if (lookahead == '*’) {

match('*’);

F(); Tprime(); }

// T' → ε (epsilon, do nothing)

}

// Production: F → ( E ) | id

void F() {

if (lookahead == '(') {

match('(‘);

E(); match(')'); }

else if (isalnum(lookahead)) {

// For simplicity, we treat 'id' as a single character
match(lookahead);

}

else {

syntaxError();

} }

int main() {

printf("Enter an arithmetic expression: ");

scanf("%s", input);

lookahead = nextToken();

// Start parsing from the start symbol E

E();

// Ensure entire input is consumed

if (lookahead == '\0') {

printf("Parsing successful!\n"); }

else { syntaxError(); }

return 0; }

Output:enter an arithmetic expression:i+i*i

Parsing sucessful

TASK 7: Design LALR bottom-up parser for the above language.

// Terminals

T_NUM // Represents numeric values (integer numbers)

T_PLUS // Represents the '+' operator

T_MULTIPLY // Represents the '*' operator

T_LPAREN // Represents '('

T_RPAREN // Represents ')'

T_END // End of input

// Non-terminals

Expression // Represents an expression

Term // Represents a term in the expression

Factor // Represents a factor, which could be a number or a sub-expression

// Grammar Rules

Expression -> Expression T_PLUS Term // Rule 1: Addition in an expression

Expression -> Term // Rule 2: Expression reduces to a Term

Term -> Term T_MULTIPLY Factor // Rule 3: Multiplication in a term

Term -> Factor // Rule 4: Term reduces to a Factor

Factor -> T_NUM // Rule 5: Factor reduces to a number

Factor -> T_LPAREN Expression T_RPAREN // Rule 6: Parenthesized
expression

TASK 7: Design LALR bottom-up parser for the above language.

#include <stdio.h>

#include <stdlib.h>

#include <ctype.h>

// Token definitions

typedef enum {

T_NUM = 256,

T_PLUS,

T_MULTIPLY,

T_LPAREN,

T_RPAREN,

T_END

} TokenType;

// Token structure

typedef struct {

TokenType type;

int value;

} Token;

// Parse stack structure

typedef struct {

int state;

int value;

} StackEntry;

#define STACK_MAX 100

StackEntry stack[STACK_MAX];

int stackTop = -1;

// Functions to manipulate the parse stack

void push(int state, int value) {

if (stackTop < STACK_MAX - 1) {

stack[++stackTop].state = state;

stack[stackTop].value = value;

} else {

printf("Stack overflow\n");

exit(1);

}}

void pop(int count) {

if (stackTop >= count - 1) {

stackTop -= count;

} else {

printf("Stack underflow\n");

exit(1);

}

}

// Lexer function to return next token from input

Token getToken(const char **input) {

while (**input == ' ') (*input)++;

if (isdigit(**input)) {

Token token = { T_NUM, 0 };

while (isdigit(**input)) {

token.value = token.value * 10 + (**input - '0');

(*input)++;

}

return token;

} else if (**input == '+') {

(*input)++;

return (Token) { T_PLUS, 0 };

} else if (**input == '*') {

(*input)++;

return (Token) { T_MULTIPLY, 0 };

} else if (**input == '(') {

(*input)++;

return (Token) { T_LPAREN, 0 };

} else if (**input == ')') {

(*input)++;

return (Token) { T_RPAREN, 0 };

} else if (**input == '\0') {

return (Token) { T_END, 0 };

} else {

printf("Unknown character: %c\n", **input);

exit(1);

}

}

// A simplified parse table (hardcoded for this example)

int parseTable[5][6] = {

{1, -1, -1, 2, -1, -1}, // state 0

{-1, 3, -1, -1, -1, 0}, // state 1

{1, -1, -1, 2, -1, -1}, // state 2

{-1, -1, 4, -1, -1, -1}, // state 3

{-1, -1, -1, -1, -1, -2} // state 4 (accept state)

};

// Reduced production actions

void reduce(int rule) {

if (rule == 0) { // expression -> expression + term

int term = stack[stackTop].value;

pop(3);

stack[stackTop].value += term;

} else if (rule == 1) { // term -> term * factor

int factor = stack[stackTop].value;

pop(3);

stack[stackTop].value *= factor;

}

}

// Main parse function

void parse(const char *input) {

stackTop = -1;

push(0, 0); // Start state

Token token = getToken(&input);

while (1) {

int state = stack[stackTop].state;

int action = parseTable[state][token.type - T_NUM];

if (action > 0) { // Shift action

push(action, token.value);

token = getToken(&input);

}

else if (action < 0) { // Reduce action

if (action == -2) { // Accept

printf("Result: %d\n", stack[stackTop].value);

break;

}

reduce(-action - 1);

} else {

printf("Syntax error\n");

break;

}

}

}

// Main function to take input and call the parser

int main() {

const char *input = "3 + 5 * 2";

printf("Parsing: %s\n", input);

parse(input);

return 0;

}

TASK 8: Write program to generate machine code from the abstract syntax tree

generated by the parser

#include <stdio.h>

#include <stdlib.h>

#include <string.h>

// Define the structure for AST nodes

typedef struct ASTNode {

char value; // Operator (+, -, *, /) or operand (0-9)

struct ASTNode *left; // Left child

struct ASTNode *right; // Right child

} ASTNode;

int temp_count = 0; // Counter for temporary registers

// Function to create a new AST node

ASTNode* createNode(char value, ASTNode* left, ASTNode* right) {

ASTNode* node = (ASTNode*)malloc(sizeof(ASTNode));

node->value = value;

node->left = left;

node->right = right;

return node;

}

// Function to generate a unique temporary register name

void newTemp(char *temp) {

sprintf(temp, "R%d", temp_count++);

}

// Recursive function to generate machine code from the AST

void generateCode(ASTNode* node) {

char leftTemp[5], rightTemp[5], resultTemp[5];

// If the node is NULL, return

if (node == NULL)

return;

// Leaf node: if both children are NULL, it's an operand

if (node->left == NULL && node->right == NULL) {

return;

}

// Recursive code generation for left and right subtrees

generateCode(node->left);

newTemp(leftTemp);

printf("MOV %s, %c\n", leftTemp, node->left->value);

generateCode(node->right);

newTemp(rightTemp);

printf("MOV %s, %c\n", rightTemp, node->right->value);

// Generate a new temporary for the result

newTemp(resultTemp);

// Generate machine code based on the operation

switch (node->value) {

case '+':

printf("MOV %s, %s\n", resultTemp, leftTemp);

printf("ADD %s, %s\n", resultTemp, rightTemp);

break;

case '-':

printf("MOV %s, %s\n", resultTemp, leftTemp);

printf("SUB %s, %s\n", resultTemp, rightTemp);

break;

case '*':

printf("MOV %s, %s\n", resultTemp, leftTemp);

printf("MUL %s, %s\n", resultTemp, rightTemp);

break;

case '/':

printf("MOV %s, %s\n", resultTemp, leftTemp);

printf("DIV %s, %s\n", resultTemp, rightTemp);

break;

default:

printf("Unsupported operation\n");

return;

}node->value=‘A’;

}

// Main function to demonstrate the code generation

int main() {

// Constructing an example AST for the expression (3 + 5) * (10 -
2)

ASTNode* ast = createNode('*',

createNode('+', createNode('3', NULL, NULL),
createNode('5', NULL, NULL)),

createNode('-', createNode(‘4', NULL, NULL),
createNode('2', NULL, NULL)));

printf("Generated Machine Code:\n");

generateCode(ast);

// Free memory

free(ast->left->left);

free(ast->left->right);

free(ast->left);

free(ast->right->left);

free(ast->right->right);

free(ast->right);

free(ast);

return 0;

}

TASK :9 Introduction to YACC.

YACC (Yet Another Compiler Compiler) :

is a tool used in the process of compiler construction.

It simplifies the creation of parsers by allowing developers to specify the
grammar of a programming language or other structured text format in a
high-level, declarative way.

YACC is widely used in systems programming and is particularly useful for
designing interpreters and compilers.

Grammar Specification:
YACC uses context-free grammars, typically written in Backus-Naur Form
(BNF), to define the syntax rules of a language.

LALR(1) Parsing:
It generates parsers based on the Look-Ahead Left-to-Right parsing method
for context-free grammars. This allows efficient parsing of a wide variety of
languages.

C Code Integration:
The actions for each rule in the grammar can include C code, enabling the
parser to perform computations or build data structures during parsing.

Flexibility and Compatibility:
YACC works seamlessly with LEX, a lexical analyzer generator. Together,
they form a powerful pair for compiler design.

Structure :

%{

/* C code or declarations to include in the generated parser */

%}

%token TOKEN_NAME /* Token declarations */

%start START_SYMBOL /* Optional: Specify the start symbol */

%%

/* Grammar rules and associated actions */

non_terminal : production1 { action1 }

| production2 { action2 }

;

%%

/* Additional C code for helper functions, main(), or global variables */

Declarations Section (%{ ... %}):

Enclosed between %{ and %}, this section includes C code, such as
#include directives, macro definitions, or global declarations.

Example:

%{

#include <stdio.h>

int yylex(); // Function prototype for lexical analyzer

void yyerror(const char *s); // Error-handling function

%}

Token Declarations (%token):

Tokens (terminal symbols) are declared here, typically corresponding to input
symbols provided by the lexer (e.g., keywords, operators).

Example:

%token NUMBER PLUS MINUS MULTIPLY DIVIDE

Precedence and Associativity (%left, %right, %nonassoc):

Defines operator precedence and associativity to resolve parsing conflicts
(e.g., shift/reduce conflicts).

Example :

%left '+' '-'

%left '*' '/'

Start Symbol (%start):

Specifies the starting non-terminal of the grammar. If omitted, the first rule's
left-hand side is the default start symbol.

Example :

%start expr

Rules Section (%%):

Contains the grammar rules that define the structure of the language.

Each rule has the following format:

non_terminal : production1 { C action code }

| production2 { C action code }

;

non_terminal: The left-hand side of the rule (a non-terminal symbol).

production1: Right-hand side of the rule (sequence of terminals and
non-terminals).

{ C action code }: Embedded C code to execute when the rule is applied
(optional).

Example :

expr : expr '+' term { printf("Addition\n"); }

| expr '-' term { printf("Subtraction\n"); }

| term

;

term : term '*' factor { printf("Multiplication\n"); }

| term '/' factor { printf("Division\n"); }

| factor

;

factor : '(' expr ')' { }

| NUMBER { printf("Number: %d\n", $1); }

;

C Code Section (After %%)

Contains any additional C code needed for the program, such as:

The main() function.

The yyerror() function for error handling.

Supporting functions or global variable definitions.

Example :

%%

int main() {

printf("Enter an expression:\n");

yyparse();

return 0;

}

void yyerror(const char *s) {

fprintf(stderr, "Error: %s\n", s);

}

Special Symbols in YACC:

$n: Refers to the value of the n-th symbol in the production (1-based index).

Example :

expr : expr '+' term { $$ = $1 + $3; }

Here, $1 refers to the value of expr,

$3 refers to term, and $$ stores the result of the rule.

$$: Represents the value of the left-hand side of the rule.

%%: Separates sections in a YACC file.

Example YACC Syntax :

This YACC file parses arithmetic expressions and evaluates their result:

%{

#include <stdio.h>

#include <stdlib.h>

%}

%token NUMBER

%left '+' '-'

%left '*' '/'

%%

expr : expr '+' expr { $$ = $1 + $3; }

| expr '-' expr { $$ = $1 - $3; }

| expr '*' expr { $$ = $1 * $3; }

| expr '/' expr { if ($3 == 0) { yyerror("Division by zero"); exit(1); } else $$ = $1 / $3; }

| '(' expr ')' { $$ = $2; }

| NUMBER { $$ = $1; }

;

%%

int main() {

printf("Enter an expression:\n");

yyparse();

return 0;

}

void yyerror(const char *s) {

fprintf(stderr, "Error: %s\n", s);

}

BNF RULES:

expr ::= term ('+' term | '-' term)*

term ::= factor ('*' factor | '/' factor)*

factor ::= '(' expr ')' | NUM

INPUT :(5 + 3) * 2

TASK 10: Convert the BNF rules into Yacc form and Write code to generate abstract

syntax tree.

//Parser.y

%{

#include <stdio.h>

#include <stdlib.h>

// Define the AST node structure

typedef struct ASTNode {

char *type;

union {

int value; // For NUM

struct { // For operators

struct ASTNode *left;

struct ASTNode *right;

} operands;

} data;

} ASTNode;

// Function prototypes for creating AST nodes

ASTNode *create_num_node(int value);

ASTNode *create_op_node(char *type, ASTNode *left, ASTNode *right);

%}

%token NUM

%left '+' '-'

%left '*' '/'

%%

expr: term

| expr '+' term { $$ = create_op_node("+", $1, $3); }

| expr '-' term { $$ = create_op_node("-", $1, $3); }

;

term: factor

| term '*' factor { $$ = create_op_node("*", $1, $3); }

| term '/' factor { $$ = create_op_node("/", $1, $3); }

;

factor: '(' expr ')' { $$ = $2; }

| NUM { $$ = create_num_node($1); }

;

%%

// Create a number node

ASTNode *create_num_node(int value) {

ASTNode *node = (ASTNode *)malloc(sizeof(ASTNode));

node->type = "NUM";

node->data.value = value;

return node;

}

// Create an operator node

ASTNode *create_op_node(char *type, ASTNode *left, ASTNode
*right) {

ASTNode *node = (ASTNode *)malloc(sizeof(ASTNode));

node->type = type;

node->data.operands.left = left;

node->data.operands.right = right;

return node;

}

// Main function and helper code

int main() {

printf("Enter expression: ");

yyparse();

return 0;

}

void yyerror(const char *s) {

fprintf(stderr, "Error: %s\n", s);

}

// lex file Lexer.l

%{

#include "y.tab.h"

%}

%%

[0-9]+ { yylval = atoi(yytext); return NUM; }

[ \t]+ { /* Ignore whitespace */ }

\n { return '\n'; }

. { return yytext[0]; } /* Match single characters */

%%

Installation and execution :

For Ubuntu/Debian:

sudo apt-get install bison flex gcc

Generate Parser Code:

yacc -d parser.y

This creates two files:

y.tab.c: Contains the parser code.

y.tab.h: Contains token definitions.

Generate Lexer Code:

lex lexer.l

This creates the file:

lex.yy.c: Contains the lexer code.

Compile the ProgramCombine the generated files (y.tab.c and lex.yy.c) and compile
them using gcc:

gcc -o ast y.tab.c lex.yy.c -lm

Here:

-o ast: Specifies the output executable file as ast

.-lm: Links the math library (optional here but useful for advanced math functions).

Run the Program

Run the compiled executable:

./ast

Test Input

Enter arithmetic expressions when prompted. For example:

Enter an expression: (5 + 3) * 2

Output:abstract syntax tree